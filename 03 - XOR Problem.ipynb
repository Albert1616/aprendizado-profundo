{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7057a01",
   "metadata": {},
   "source": [
    "# Resolvendo o XOR com PyTorch\n",
    "\n",
    "Este notebook é uma demonstração simples e direta de como as redes neurais podem resolver problemas não linearmente separáveis, como o clássico problema **XOR (OU Exclusivo)**.\n",
    "\n",
    "O objetivo principal é visualizar as **fronteiras de decisão** aprendidas por dois modelos:\n",
    "1.  Um modelo linear simples, que **falhará** em resolver o problema.\n",
    "2.  Um Perceptron de Múltiplas Camadas (MLP) com uma camada oculta, que **terá sucesso**.\n",
    "\n",
    "Isso ilustrará de forma clara a importância das camadas ocultas e das funções de ativação não lineares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7862ed09",
   "metadata": {},
   "source": [
    "### 1. Configuração e Preparação dos Dados\n",
    "\n",
    "Primeiro, vamos importar as bibliotecas necessárias e definir os dados do problema XOR. Também criaremos uma função auxiliar para plotar as fronteiras de decisão, que será o coração visual deste notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76394107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Dados do problema XOR\n",
    "# Entradas (features)\n",
    "X = torch.tensor([\n",
    "    [0.0, 0.0],\n",
    "    [0.0, 1.0],\n",
    "    [1.0, 0.0],\n",
    "    [1.0, 1.0]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Rótulos (labels)\n",
    "y = torch.tensor([\n",
    "    [0.0],\n",
    "    [1.0],\n",
    "    [1.0],\n",
    "    [0.0]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Plot inicial dos dados\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y.squeeze(), cmap='bwr', s=100, edgecolors='k')\n",
    "plt.title(\"O Problema XOR\")\n",
    "plt.xlabel(\"Entrada 1\")\n",
    "plt.ylabel(\"Entrada 2\")\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6791ca91",
   "metadata": {},
   "source": [
    "### Tentativa 1: Um Modelo Linear\n",
    "\n",
    "Vamos começar com o modelo mais simples possível: uma única camada linear. Este modelo só consegue aprender fronteiras de decisão lineares (uma linha reta). Como o XOR não é linearmente separável, esperamos que este modelo falhe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363cf91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo com uma única camada linear\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        # Mapeia 2 entradas para 1 saída\n",
    "        self.linear = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Treinamento do modelo linear\n",
    "linear_model = LinearModel()\n",
    "# BCEWithLogitsLoss é mais estável numericamente que Sigmoid + BCELoss\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(linear_model.parameters(), lr=0.1)\n",
    "\n",
    "epochs = 5000\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    outputs = linear_model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    \n",
    "    # Backward e otimização\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f\"Treinamento do modelo linear concluído. Perda final: {loss.item():.4f}\")\n",
    "\n",
    "# Avaliação\n",
    "with torch.no_grad():\n",
    "    predictions = torch.sigmoid(linear_model(X))\n",
    "    print(\"\\nPrevisões do Modelo Linear (probabilidades):\")\n",
    "    print(predictions)\n",
    "    print(\"\\nPrevisões Finais (arredondado):\")\n",
    "    print(torch.round(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b9b2b",
   "metadata": {},
   "source": [
    "### Tentativa 2: Adicionando uma Camada Oculta\n",
    "\n",
    "Agora, vamos adicionar uma camada oculta e uma função de ativação não linear (`ReLU`). Isso transforma nosso modelo em um Perceptron de Múltiplas Camadas (MLP), permitindo que ele aprenda fronteiras de decisão complexas e não lineares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f5196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo MLP com uma camada oculta\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(2, 4) # 2 entradas, 4 neurônios na camada oculta\n",
    "        self.layer2 = nn.Linear(4, 1) # 4 da oculta, 1 neurônio na saída\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = self.layer2(x) # A BCEWithLogitsLoss aplica a sigmoid internamente\n",
    "        return x\n",
    "\n",
    "# Treinamento do modelo MLP\n",
    "mlp_model = MLPModel()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(mlp_model.parameters(), lr=0.1)\n",
    "\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    outputs = mlp_model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(f\"Treinamento do modelo MLP concluído. Perda final: {loss.item():.4f}\")\n",
    "\n",
    "# Avaliação\n",
    "with torch.no_grad():\n",
    "    predictions = torch.sigmoid(mlp_model(X))\n",
    "    print(\"\\nPrevisões do Modelo MLP (probabilidades):\")\n",
    "    print(predictions)\n",
    "    print(\"\\nPrevisões Finais (arredondado):\")\n",
    "    print(torch.round(predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
