{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a35a7d2",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "Este notebook explora o conceito de Transfer Learning (Aprendizagem por Transferência), uma técnica em deep learning que consiste em reutilizar um modelo pré-treinado em uma nova tarefa. Em vez de treinar uma rede neural do zero, o que exige grandes volumes de dados e poder computacional, podemos aproveitar o conhecimento encapsulado em modelos que foram treinados em datasets massivos, como o ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ecc525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f355f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a54d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "if not os.path.exists('data/hymenoptera_data'):\n",
    "    url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n",
    "    response = requests.get(url)\n",
    "    with zipfile.ZipFile(BytesIO(response.content)) as z:\n",
    "        z.extractall(\"data/hymenoptera_data\")\n",
    "    print(\"Dataset 'hymenoptera_data' baixado e extraído.\")\n",
    "else:\n",
    "    print(\"Dataset 'hymenoptera_data' já existe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7197830",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.class_names = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.class_names)}\n",
    "\n",
    "        self.data = []\n",
    "        for class_name in self.class_names:\n",
    "            class_dir = os.path.join(self.root_dir, class_name)\n",
    "            for filename in os.listdir(class_dir):\n",
    "                if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    path = os.path.join(class_dir, filename)\n",
    "                    item = (path, self.class_to_idx[class_name])\n",
    "                    self.data.append(item)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.data[idx]\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070beb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'data/hymenoptera_data'\n",
    "\n",
    "# Criando instâncias de Dataset\n",
    "train_dataset = CustomImageDataset(os.path.join(data_dir, 'train'), data_transforms['train'])\n",
    "val_dataset = CustomImageDataset(os.path.join(data_dir, 'val'), data_transforms['val'])\n",
    "\n",
    "# Criando instâncias de DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4)\n",
    "\n",
    "# Obtendo informações\n",
    "class_names = train_dataset.class_names\n",
    "train_size = len(train_dataset)\n",
    "val_size = len(val_dataset)\n",
    "\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Tamanho do dataset de treino: {train_size}\")\n",
    "print(f\"Tamanho do dataset de validação: {val_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0804974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Função para exibir um tensor de imagem.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "# Obtém um batch de dados de treino\n",
    "inputs, classes = next(iter(train_dataloader))\n",
    "\n",
    "# Cria uma grade a partir do batch\n",
    "out = utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a493bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=25):\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "        for phase, loader in [('train', train_loader), ('val', val_loader)]:\n",
    "            model.train(phase == 'train')\n",
    "            running_loss, running_corrects = 0.0, 0\n",
    "            size = len(loader.dataset)\n",
    "\n",
    "            loop = tqdm(loader, desc=f'{phase.capitalize()}')\n",
    "            for inputs, labels in loop:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels)\n",
    "\n",
    "            epoch_loss = running_loss / size\n",
    "            epoch_acc = running_corrects.double() / size\n",
    "            history[f'{phase}_loss'].append(epoch_loss)\n",
    "            history[f'{phase}_acc'].append(epoch_acc.item())\n",
    "\n",
    "            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    return history\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    ax1.plot(history['train_acc'], label='Train Accuracy')\n",
    "    ax1.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.plot(history['train_loss'], label='Train Loss')\n",
    "    ax2.plot(history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522cdd2d",
   "metadata": {},
   "source": [
    "## Treinamento de um Modelo Baseline\n",
    "\n",
    "Para entender o efeito do transfer learning, primeiro treinaremos uma rede convolucional (CNN) simples a partir do zero. Dado o tamanho reduzido do nosso dataset, é altamente provável que este modelo sofra de overfitting, o que servirá como um ponto de referência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbfdba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=len(class_names)):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 56 * 56, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "baseline_model = SimpleCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e0624",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_baseline = optim.Adam(baseline_model.parameters(), lr=0.001)\n",
    "\n",
    "history_baseline = train_model(\n",
    "    baseline_model, criterion, optimizer_baseline, train_dataloader, val_dataloader, num_epochs=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c47e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a6eca",
   "metadata": {},
   "source": [
    "## Modelos Pré-treinados\n",
    "\n",
    "O `torchvision.models` oferece acesso a diversas arquiteturas de modelos já treinados no dataset ImageNet. Esses modelos aprenderam a extrair hierarquias ricas de características (features), que podem ser aproveitadas em outras tarefas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b5d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando um modelo ResNet-50 pré-treinado\n",
    "weights = models.ResNet50_Weights.DEFAULT\n",
    "resnet50_pretrained = models.resnet50(weights=weights)\n",
    "\n",
    "# A última camada 'fc' (fully connected) tem 1000 saídas,\n",
    "# correspondentes às 1000 classes do ImageNet.\n",
    "print(resnet50_pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cb5a1a",
   "metadata": {},
   "source": [
    "### Usando um Modelo Pré-treinado para Inferência\n",
    "\n",
    "Um modelo pré-treinado pode ser usado diretamente para inferência. Basta carregá-lo, colocá-lo em modo de avaliação com `.eval()` e passar uma imagem pré-processada. A saída será um vetor de scores para as 1000 classes do ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef092a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.uni-jena.de/unijenamedia/387585/elefant.jpg?height=428&width=760\"\n",
    "response = requests.get(url, stream=True)\n",
    "img = Image.open(response.raw)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92911dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = data_transforms['val']\n",
    "img_tensor = preprocess(img).unsqueeze(0)\n",
    "\n",
    "print(preprocess)\n",
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf1b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_pretrained.eval()\n",
    "with torch.no_grad():\n",
    "    output = resnet50_pretrained(img_tensor)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a035dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(f\"Classe: {weights.meta['categories'][top5_catid[i]]}, Probabilidade: {top5_prob[i].item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ff1bc2",
   "metadata": {},
   "source": [
    "## Transfer Learning: Congelando Camadas (Freezing)\n",
    "\n",
    "A estratégia de \"feature extraction\" consiste em congelar os pesos das camadas convolucionais de um modelo pré-treinado e substituir a camada de classificação final por uma nova, adequada ao nosso problema. Apenas os pesos dessa nova camada serão treinados, o que é computacionalmente eficiente e previne overfitting em datasets pequenos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0c21da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model_conv = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# Congelar todos os parâmetros da rede\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(model_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3c0edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model_conv.fc.in_features\n",
    "\n",
    "# Substituir a camada 'fc' por uma nova camada Linear\n",
    "# Os parâmetros desta nova camada terão `requires_grad=True` por padrão\n",
    "model_conv.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "print(\"Estrutura da última camada modificada:\")\n",
    "print(model_conv.fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996cee14",
   "metadata": {},
   "source": [
    "## Treinando o Modelo com Transfer Learning\n",
    "\n",
    "Agora, vamos treinar o modelo modificado. O otimizador Adam será configurado para atualizar apenas os parâmetros da nova camada de classificação. Esperamos ver uma convergência muito mais rápida e uma acurácia de validação significativamente maior em comparação com o modelo baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee36ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_conv = optim.Adam(model_conv.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Treinar o modelo\n",
    "history_conv = train_model(\n",
    "    model_conv, criterion, optimizer_conv, train_dataloader, val_dataloader, num_epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152264f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded0b26e",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306fa620",
   "metadata": {},
   "source": [
    "### Exercício 1\n",
    "\n",
    "Descongele mais das últimas camadas (à sua escolha), por exemplo `model.layer4[1]`, e treine novamente o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f11b08",
   "metadata": {},
   "source": [
    "### Exercício 2\n",
    "\n",
    "Escolha outro modelo pré-treinado em [Torchvision Models](https://docs.pytorch.org/vision/main/models.html) e substitua no modelo. Lembre-se de alterar a última camada de classificação."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
