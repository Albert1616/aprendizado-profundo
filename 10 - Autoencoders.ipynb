{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f519d73",
   "metadata": {},
   "source": [
    "# Representações Latentes e Autoencoders\n",
    "\n",
    "Neste notebook, exploraremos o conceito de representações latentes e como os autoencoders podem ser utilizados para aprendê-las de forma não supervisionada. Abordaremos os seguintes tópicos:\n",
    "\n",
    "* **Representações Latentes**:\n",
    "    * Definição formal e o objetivo de aprender representações de dados em espaços de menor dimensionalidade.\n",
    "    * Visualização do espaço latente com o algoritmo t-SNE (t-Distributed Stochastic Neighbor Embedding).\n",
    "    * Exemplo prático de treinamento de um codificador (encoder) para a tarefa de classificação e a subsequente visualização de suas representações latentes para o dataset MNIST.\n",
    "\n",
    "* **Autoencoders**:\n",
    "    * Arquitetura fundamental de um autoencoder (encoder-decoder).\n",
    "    * Implementação e treinamento de um autoencoder para reconstruir imagens do MNIST.\n",
    "    * Visualização de imagens originais e reconstruídas.\n",
    "\n",
    "* **Denoising Autoencoders**:\n",
    "    * Conceito e formulação de autoencoders com remoção de ruído.\n",
    "    * Aplicação prática na remoção de ruído de imagens do MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9aa904",
   "metadata": {},
   "source": [
    "## Representações Latentes\n",
    "\n",
    "No contexto de Deep Learning, uma representação latente é uma codificação interna dos dados de entrada que emerge como resultado do processo de treinamento de uma rede neural para uma tarefa específica. Em vez de ser um resultado de um algoritmo de redução de dimensionalidade pré-definido, o espaço latente é aprendido dinamicamente.\n",
    "\n",
    "As redes neurais profundas são compostas por uma sequência de camadas. Cada camada executa uma transformação sobre seu dado de entrada, e o resultado é uma representação progressivamente mais abstrata. A saída de qualquer camada intermediária de uma rede pode ser considerada uma representação latente.\n",
    "\n",
    "A estrutura e as propriedades deste espaço latente são diretamente influenciadas pela função objetivo (loss function) que o modelo otimiza.\n",
    "\n",
    "Em Aprendizagem Supervisionada (e.g., Classificação), o modelo é treinado para minimizar um erro de classificação (como a Entropia Cruzada). Para isso, o algoritmo de backpropagation ajusta os pesos da rede de forma a transformar os dados de entrada em representações internas que tornem as classes o mais separáveis possível. Um espaço latente ideal, neste caso, agrupará amostras da mesma classe em regiões coesas e distintas, idealmente permitindo uma separação linear por parte das camadas finais da rede. A representação aprende a reter apenas as características discriminativas para a tarefa.\n",
    "\n",
    "Formalmente, o mapeamento para o espaço latente é uma função parametrizada $\\mathbf{z} = f_{\\theta}(x)$, onde $\\theta$ representa os pesos da rede (o *encoder*) e $\\mathbf{z} \\in \\mathbb{R}^m$ é o vetor latente. Esses parâmetros $\\theta$ são aprendidos através da otimização de gradiente descendente para minimizar a função de perda da tarefa final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad7c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee7037",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26d453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Transformação\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_data = datasets.MNIST(\"./data\", train=True, download=True, transform=transform)\n",
    "test_data  = datasets.MNIST(\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Subsets menores\n",
    "train_subset = Subset(train_data, torch.randperm(len(train_data))[:10000])\n",
    "val_subset   = Subset(test_data,  torch.randperm(len(test_data))[:1000])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_subset, batch_size=64)\n",
    "\n",
    "print(len(train_subset), len(val_subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8177bdad",
   "metadata": {},
   "source": [
    "### Treinando um Modelo para Aprender Representações\n",
    "\n",
    "Para gerar um espaço latente significativo, treinaremos uma Rede Neural na tarefa de classificação do MNIST. As camadas intermediárias desta rede aprenderão a extrair características relevantes dos dados, e a saída de uma dessas camadas servirá como nossa representação latente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7febb0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(64, latent_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.classifier_head = nn.Linear(latent_dim, 10)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.flatten(x)\n",
    "        latent = self.encoder(x)\n",
    "        return latent\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.encode(x)\n",
    "        logits = self.classifier_head(latent)\n",
    "        return logits\n",
    "\n",
    "model = Classifier().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3881b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02af4a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "epochs = 10\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ---- Treino ----\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "    \n",
    "    history[\"train_loss\"].append(total_loss / len(train_loader))\n",
    "    history[\"train_acc\"].append(100 * correct / total)\n",
    "\n",
    "    # ---- Validação ----\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    \n",
    "    history[\"val_loss\"].append(val_loss / len(val_loader))\n",
    "    history[\"val_acc\"].append(100 * correct / total)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "          f\"Train Loss: {history['train_loss'][-1]:.4f}, \"\n",
    "          f\"Train Acc: {history['train_acc'][-1]:.2f}% | \"\n",
    "          f\"Val Loss: {history['val_loss'][-1]:.4f}, \"\n",
    "          f\"Val Acc: {history['val_acc'][-1]:.2f}%\")\n",
    "\n",
    "# ---- Plots ----\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(history[\"val_loss\"], label=\"Val Loss\", linestyle=\"--\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history[\"train_acc\"], label=\"Train Acc\")\n",
    "plt.plot(history[\"val_acc\"], label=\"Val Acc\", linestyle=\"--\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbea15f",
   "metadata": {},
   "source": [
    "### Visualização com t-SNE\n",
    "\n",
    "O t-Distributed Stochastic Neighbor Embedding (t-SNE) é um algoritmo não linear de redução de dimensionalidade utilizado primariamente para a visualização de datasets de alta dimensão. Sua principal função é mapear a similaridade entre pontos de dados de um espaço de alta dimensão para um espaço de baixa dimensão (geralmente 2D ou 3D).\n",
    "\n",
    "O t-SNE modela a probabilidade condicional de que um ponto $x_i$ escolheria $x_j$ como seu vizinho, baseando-se em uma distribuição Gaussiana centrada em $x_i$. Em seguida, ele tenta construir uma distribuição de probabilidade similar sobre os pontos no mapa de baixa dimensão. A otimização é realizada minimizando a divergência de Kullback-Leibler (KL) entre as duas distribuições de probabilidades, a do espaço original e a do espaço de baixa dimensão. O resultado é um mapa que revela a estrutura de clusters dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee6882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "model.eval()\n",
    "all_latents = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in val_loader:\n",
    "        X = X.to(device)\n",
    "        latent = model.encode(X)\n",
    "        all_latents.append(latent.cpu().numpy())\n",
    "        all_labels.append(y.cpu().numpy())\n",
    "\n",
    "latent_space_test = np.concatenate(all_latents, axis=0)\n",
    "labels_test = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, verbose=1, perplexity=30, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(latent_space_test)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=labels_test, cmap='tab10', s=10)\n",
    "plt.title('Visualização do Espaço Latente com t-SNE', fontsize=16)\n",
    "plt.xlabel('Componente t-SNE 1')\n",
    "plt.ylabel('Componente t-SNE 2')\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=list(range(10)))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba13185",
   "metadata": {},
   "source": [
    "## Autoencoders\n",
    "\n",
    "Um Autoencoder é um tipo de rede neural artificial utilizada para aprender representações de dados de forma não supervisionada. A arquitetura é composta por duas partes principais:\n",
    "\n",
    "1.  **Encoder ($f$)**: Mapeia a entrada $x$ para uma representação latente $z$ de menor dimensão. $z = f(x)$.\n",
    "2.  **Decoder ($g$)**: Tenta reconstruir a entrada original a partir da representação latente $z$. $\\hat{x} = g(z)$.\n",
    "\n",
    "O objetivo do treinamento é minimizar o erro de reconstrução, que é a diferença entre a entrada original $x$ e a sua reconstrução $\\hat{x}$. Uma função de perda comum para essa tarefa é o Erro Quadrático Médio (Mean Squared Error - MSE).\n",
    "\n",
    "$$ \\mathcal{L}(x, \\hat{x}) = \\mathcal{L}(x, g(f(x))) = \\frac{1}{N} \\sum_{i=1}^{N} (x_i - \\hat{x}_i)^2 $$\n",
    "\n",
    "O gargalo informacional imposto pela camada latente força o autoencoder a aprender apenas as variações mais importantes nos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8020f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encoding_dim=8):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, encoding_dim),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 28 * 28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "ae_model = Autoencoder().to(device)\n",
    "print(ae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e1396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_criterion = nn.MSELoss()\n",
    "ae_optimizer = torch.optim.Adam(ae_model.parameters(), lr=1e-3, weight_decay=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f0bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "ae_model.train()\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for X, _ in train_loader:\n",
    "        X = X.view(X.size(0), -1).to(device)\n",
    "        \n",
    "        # Forward\n",
    "        recon = ae_model(X)\n",
    "        loss = ae_criterion(recon, X)\n",
    "\n",
    "        # Backward\n",
    "        ae_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        ae_optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(1, epochs+1), train_losses, marker=\"o\")\n",
    "plt.title(\"Training Loss (Autoencoder)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08288b80",
   "metadata": {},
   "source": [
    "### Visualização das Reconstruções\n",
    "\n",
    "Após o treinamento, podemos passar imagens do conjunto de teste pelo autoencoder para obter suas reconstruções. Comparar visualmente as imagens originais com as reconstruídas nos dá uma avaliação qualitativa do desempenho do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a857b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização das imagens reconstruídas\n",
    "ae_model.eval()\n",
    "n = 10\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Pega um batch de dados de validação\n",
    "    data_iter = iter(val_loader)\n",
    "    images, _ = next(data_iter)\n",
    "    images_flat = images.view(images.size(0), -1).to(device)\n",
    "    \n",
    "    # Gera as reconstruções\n",
    "    reconstructed_flat = ae_model(images_flat)\n",
    "    \n",
    "    # Converte para numpy para plotar\n",
    "    original_images = images.cpu().numpy()\n",
    "    reconstructed_images = reconstructed_flat.view(-1, 1, 28, 28).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e822f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "for i in range(n):\n",
    "    # Imagem original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(original_images[i].squeeze(), cmap='gray', vmin=0, vmax=1)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if i == n//2:\n",
    "        ax.set_title('Imagens Originais')\n",
    "\n",
    "    # Imagem reconstruída\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(reconstructed_images[i].squeeze(), cmap='gray', vmin=0, vmax=1)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if i == n//2:\n",
    "        ax.set_title('Imagens Reconstruídas')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203df1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_model.eval()\n",
    "ae_all_latents = []\n",
    "ae_all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in val_loader:\n",
    "        X = X.view(X.size(0), -1).to(device)\n",
    "        latent = ae_model.encoder(X)\n",
    "        ae_all_latents.append(latent.cpu().numpy())\n",
    "        ae_all_labels.append(y.cpu().numpy())\n",
    "\n",
    "ae_latent_space_test = np.concatenate(ae_all_latents, axis=0)\n",
    "ae_labels_test = np.concatenate(ae_all_labels, axis=0)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, verbose=1, perplexity=30, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(ae_latent_space_test)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=labels_test, cmap='tab10', s=10)\n",
    "plt.title('Visualização do Espaço Latente com t-SNE', fontsize=16)\n",
    "plt.xlabel('Componente t-SNE 1')\n",
    "plt.ylabel('Componente t-SNE 2')\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=list(range(10)))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb11fae3",
   "metadata": {},
   "source": [
    "## Denoising Autoencoders\n",
    "\n",
    "Um Denoising Autoencoder é uma variação do autoencoder padrão que é treinado para reconstruir uma entrada limpa a partir de uma versão corrompida (ruidosa) da mesma. A hipótese é que, para realizar essa tarefa, o modelo é forçado a aprender características mais robustas e a extrair a estrutura subjacente dos dados, em vez de simplesmente aprender uma função identidade.\n",
    "\n",
    "O processo de treinamento envolve:\n",
    "1.  Corromper a imagem de entrada $x$ para obter $\\tilde{x}$.\n",
    "2.  Alimentar $\\tilde{x}$ ao encoder para obter $z = f(\\tilde{x})$.\n",
    "3.  Alimentar $z$ ao decoder para obter a reconstrução $\\hat{x} = g(z)$.\n",
    "4.  Minimizar a perda entre a reconstrução $\\hat{x}$ e a imagem original *limpa* $x$.\n",
    "\n",
    "$$ \\mathcal{L}(x, \\hat{x}) = \\mathcal{L}(x, g(f(\\tilde{x}))) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5f9f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.4\n",
    "\n",
    "data_iter = iter(val_loader)\n",
    "images, _ = next(data_iter)\n",
    "images_clean_flat = images.view(images.size(0), -1).to(device)\n",
    "\n",
    "# Cria a versão com ruído\n",
    "noise = torch.randn_like(images_clean_flat) * noise_factor\n",
    "images_noisy_flat = torch.clip(images_clean_flat + noise, 0., 1.)\n",
    "\n",
    "# Prepara para plotagem\n",
    "original_imgs = images_clean_flat.cpu().numpy().reshape(-1, 28, 28)\n",
    "noisy_imgs = images_noisy_flat.cpu().numpy().reshape(-1, 28, 28)\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "for i in range(n):\n",
    "    # Imagem original (limpa)\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(original_imgs[i], cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if i == n//2:\n",
    "        ax.set_title('Original')\n",
    "\n",
    "    # Imagem com ruído (entrada do modelo)\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(noisy_imgs[i], cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if i == n//2:\n",
    "        ax.set_title('Com Ruído')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f37e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoising_ae_model = Autoencoder().to(device)\n",
    "dae_loss_fn = nn.MSELoss()\n",
    "dae_optimizer = torch.optim.Adam(denoising_ae_model.parameters(), lr=1e-3, weight_decay=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a834166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = 25\n",
    "denoising_ae_model.train()\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for X, _ in train_loader:\n",
    "        X_clean = X.view(X.size(0), -1).to(device)\n",
    "\n",
    "        # Adiciona ruído\n",
    "        noise = torch.randn_like(X_clean) * noise_factor\n",
    "        X_noisy = torch.clamp(X_clean + noise, 0., 1.)\n",
    "\n",
    "        # Predição e perda (com imagem limpa)\n",
    "        recon = denoising_ae_model(X_noisy)\n",
    "        loss = dae_loss_fn(recon, X_clean)\n",
    "\n",
    "        # Backpropagation\n",
    "        dae_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        dae_optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(1, epochs+1), train_losses, marker=\"o\")\n",
    "plt.title(\"Training Loss (Denoising Autoencoder)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e2c05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoising_ae_model.eval()\n",
    "n = 10\n",
    "\n",
    "with torch.no_grad():\n",
    "    data_iter = iter(val_loader)\n",
    "    images, _ = next(data_iter)\n",
    "    images_clean_flat = images.view(images.size(0), -1).to(device)\n",
    "    \n",
    "    # Cria a versão com ruído\n",
    "    noise = torch.randn_like(images_clean_flat) * noise_factor\n",
    "    images_noisy_flat = torch.clip(images_clean_flat + noise, 0., 1.)\n",
    "    \n",
    "    # Gera a reconstrução (denoised)\n",
    "    denoised_flat = denoising_ae_model(images_noisy_flat)\n",
    "    \n",
    "    # Prepara para plotagem\n",
    "    original_imgs = images_clean_flat.cpu().numpy().reshape(-1, 28, 28)\n",
    "    noisy_imgs = images_noisy_flat.cpu().numpy().reshape(-1, 28, 28)\n",
    "    denoised_imgs = denoised_flat.cpu().numpy().reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8059850",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "for i in range(n):\n",
    "    # Imagem original (limpa)\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(original_imgs[i], cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if i == n//2:\n",
    "        ax.set_title('Original')\n",
    "\n",
    "    # Imagem com ruído (entrada do modelo)\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(noisy_imgs[i], cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if i == n//2:\n",
    "        ax.set_title('Com Ruído')\n",
    "\n",
    "    # Imagem reconstruída (denoised)\n",
    "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "    plt.imshow(denoised_imgs[i], cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if i == n//2:\n",
    "        ax.set_title('Reconstruída (Denoised)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
