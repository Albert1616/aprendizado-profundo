{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b56be23e",
   "metadata": {},
   "source": [
    "# YOLO\n",
    "\n",
    "Este notebook abordará a utilização e o ajuste fino (fine-tuning) da arquitetura **You Only Look Once (YOLO)**, especificamente implementada pela biblioteca **Ultralytics**. O YOLO é um detector de objetos em tempo real que reformulou a detecção ao tratar o problema como uma regressão única. O fine-tuning é uma técnica crucial no Deep Learning que permite adaptar um modelo pré-treinado em um *dataset* vasto (como COCO) para uma tarefa específica com um *dataset* menor e mais especializado, aproveitando o conhecimento hierárquico já aprendido pelo modelo base.\n",
    "\n",
    "A biblioteca **Ultralytics YOLO** fornece uma interface de alto nível e eficiente para diversas versões do YOLO (YOLOv8, YOLOv5, etc.), tornando a inferência e o treinamento acessíveis. A filosofia é focar na usabilidade sem sacrificar a performance.\n",
    "\n",
    "Para começar, demonstraremos a inferência básica, que é o processo de usar um modelo treinado para fazer previsões em novos dados. Utilizaremos um modelo pré-treinado em um *dataset* padrão para a detecção de objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab81764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação da biblioteca ultralytics. Pode ser necessário reiniciar o runtime.\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cea3af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import ultralytics\n",
    "print(f\"Ultralytics version: {ultralytics.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0da397",
   "metadata": {},
   "source": [
    "## Inferência\n",
    "\n",
    "O processo de inferência com o YOLO da Ultralytics é notavelmente simples. Basta carregar um modelo pré-treinado, como o `yolov8n.pt` (a versão *nano* do YOLOv8, que oferece um bom equilíbrio entre velocidade e precisão) e chamar o método `predict` com a fonte de dados desejada.\n",
    "\n",
    "### Inferência em Imagens\n",
    "\n",
    "A inferência em uma imagem envolve o carregamento do arquivo e a obtenção das caixas delimitadoras (*bounding boxes*), classes e pontuações de confiança para os objetos detectados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214dcc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('data/yolov8n.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82f388e",
   "metadata": {},
   "source": [
    "Executando a inferência em uma imagem de exemplo (pode ser um URL ou caminho local). O Ultralytics baixa automaticamente os pesos do modelo na primeira execução. O modo `save=True` salva a imagem com as detecções desenhadas. Usaremos uma imagem de exemplo que o próprio Ultralytics pode acessar.\n",
    "\n",
    "É importante notar que o argumento `source` aceita caminhos para arquivos locais, URLs e até mesmo index de câmeras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53cfb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(source='https://ultralytics.com/images/bus.jpg', save=False, conf=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0feb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    r.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f4aa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'results' é uma lista de objetos Results, um para cada fonte de entrada (no caso, apenas um).\n",
    "for r in results:\n",
    "    print(f\"Número de objetos detectados: {len(r.boxes)}\")\n",
    "    for box in r.boxes:\n",
    "        print(f\"Coordenadas: {box.xyxy.cpu().numpy()[0]} - Confiança: {box.conf.cpu().numpy()[0]:.2f} - Classe: {box.cls.cpu().numpy()[0]:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c0f759",
   "metadata": {},
   "source": [
    "## Fine-tuning\n",
    "\n",
    "O **Fine-tuning** é a parte central da transferência de aprendizado (*Transfer Learning*). A premissa é que os pesos de um modelo treinado em um *dataset* genérico (como o COCO, que contém 80 classes gerais) já capturaram características de baixo nível (bordas, texturas, formas) e de alto nível (partes de objetos) que são úteis para tarefas correlatas.\n",
    "\n",
    "Ao realizar o *fine-tuning*, carregamos esses pesos pré-treinados e continuamos o treinamento em nosso *dataset* específico, geralmente com uma **taxa de aprendizado** (*learning rate*) muito menor, para evitar a destruição das representações úteis aprendidas previamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620e880e",
   "metadata": {},
   "source": [
    "### Carregamento do Dataset no Padrão YOLO\n",
    "\n",
    "O Ultralytics YOLO espera que o *dataset* esteja em um formato específico. O padrão de estrutura de diretórios é importante:\n",
    "\n",
    "```\n",
    "\n",
    "dataset_name/\n",
    "│\n",
    "├── images/\n",
    "│   ├── train/\n",
    "│   ├── val/\n",
    "│   └── test/        # opcional\n",
    "│\n",
    "└── labels/\n",
    "    ├── train/\n",
    "    ├── val/\n",
    "    └── test/        # opcional\n",
    "```\n",
    "\n",
    "O arquivo de configuração `YAML` deve conter os caminhos para as pastas, o número de classes (`nc`) e os nomes das classes (`names`).\n",
    "\n",
    "Utilizaremos um pequeno *dataset* público para fins didáticos. O dataset de **frutas (Fruits-360)**, adaptado para o padrão YOLO, é um bom exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b987a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"data/fruit-detection/Fruits-detection/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef16749",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L -o data/fruit-detection.zip https://www.kaggle.com/api/v1/datasets/download/lakshaytyagi01/fruit-detection\n",
    "!unzip -q data/fruit-detection.zip -d data/fruit-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4cf14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names:\n",
    "# - Apple\n",
    "# - Banana\n",
    "# - Grape\n",
    "# - Orange\n",
    "# - Pineapple\n",
    "# - Watermelon\n",
    "# nc: 6\n",
    "# test: test/images\n",
    "# train: train/images\n",
    "# val: valid/images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9028b0b6",
   "metadata": {},
   "source": [
    "###  Execução do Fine-tuning\n",
    "\n",
    "O fine-tuning é realizado utilizando o comando `model.train()`. É essencial carregar um modelo pré-treinado (como o `yolov8n.pt`) para inicializar os pesos.\n",
    "\n",
    "Os principais hiperparâmetros a serem configurados são:\n",
    "* `data`: O caminho para o arquivo YAML de configuração do *dataset*.\n",
    "* `epochs`: O número de épocas de treinamento. Para fine-tuning, geralmente são necessárias poucas épocas (10-50).\n",
    "* `imgsz`: O tamanho da imagem de entrada.\n",
    "* `batch`: O tamanho do *batch*. Deve ser ajustado à memória da GPU.\n",
    "\n",
    "O processo de treinamento irá ajustar os pesos do modelo pré-treinado para as classes e características específicas do novo *dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a74e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o modelo pré-treinado novamente\n",
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230c70a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train(\n",
    "    data=os.path.join(DATASET_DIR, \"data.yaml\"),\n",
    "    epochs=1,\n",
    "    imgsz=640,\n",
    "    batch=32,\n",
    "    name='yolov8n_fruits_finetune'\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning concluído. O modelo treinado (best.pt) foi salvo em 'runs/detect/yolov8n_fruits_finetune/weights'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a98791",
   "metadata": {},
   "source": [
    "## Análise e Inferência com o Modelo Ajustado\n",
    "\n",
    "Após o treinamento, o modelo com o melhor desempenho (*best.pt*) é salvo. É fundamental avaliar o modelo ajustado para garantir que ele aprendeu a detectar as novas classes de interesse de forma eficaz.\n",
    "\n",
    "O principal indicador de desempenho em detecção de objetos é o **mAP (mean Average Precision)**, que agrega as curvas de Precision-Recall para cada classe.\n",
    "\n",
    "$$\n",
    "mAP = \\frac{1}{N_{cl}} \\sum_{i=1}^{N_{cl}} AP_i\n",
    "$$\n",
    "\n",
    "Onde $N_{cl}$ é o número de classes e $AP_i$ é a Precisão Média para a classe $i$. O Ultralytics geralmente reporta o $mAP50$ (mAP com IoU - *Intersection over Union* - de 0.5) e o $mAP50-95$ (média do mAP em vários *thresholds* de IoU de 0.5 a 0.95)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2f7020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o modelo ajustado (best.pt)\n",
    "tuned_model = YOLO('runs/detect/yolov8n_fruits_finetune/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbaa7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "val_dir = os.path.join(DATASET_DIR, \"valid/images\")\n",
    "image_paths = glob.glob(val_dir + \"/*.jpg\")\n",
    "sample_paths = random.sample(image_paths, n)\n",
    "\n",
    "for img_path in sample_paths:\n",
    "    results = model.predict(source=img_path, conf=0.25, verbose=False)\n",
    "    annotated_array = results[0].plot()  # BGR\n",
    "    annotated_img = Image.fromarray(annotated_array[:, :, ::-1])  # agora RGB\n",
    "    \n",
    "    print(f\"Arquivo: {img_path}\")\n",
    "    display(annotated_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
