{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b644eccb",
   "metadata": {},
   "source": [
    "# Redes Siamesas\n",
    "\n",
    "Este notebook introduz o conceito de Redes Siamesas (Siamese Networks), uma arquitetura de rede neural projetada não para classificar entradas, mas para aprender um espaço de características (embedding) onde a distância entre amostras semelhantes é minimizada e a distância entre amostras distintas é maximizada. Utilizaremos o dataset Labeled Faces in the Wild (LFW) para treinar um modelo capaz de verificar se dois retratos faciais pertencem à mesma pessoa. A implementação será realizada em PyTorch, com foco na definição da arquitetura, na função de custo (Contrastive Loss) e no processo de inferência para verificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4203d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from sklearn.datasets import fetch_lfw_pairs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13dbd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905ccc9e",
   "metadata": {},
   "source": [
    "### Carregamento e Preparação do Dataset (LFW)\n",
    "\n",
    "Utilizaremos o dataset Labeled Faces in the Wild (LFW), especificamente a versão pré-processada em pares disponibilizada pelo `scikit-learn`. Este conjunto de dados já fornece pares de imagens rotulados como \"genuínos\" (mesma pessoa, label 1) ou \"impostores\" (pessoas diferentes, label 0). Realizaremos o download e, em seguida, dividiremos o conjunto de treinamento original em um conjunto de treinamento e um conjunto de validação para monitorar o aprendizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed24a412",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw = fetch_lfw_pairs(subset='train', resize=0.5, color=False)\n",
    "\n",
    "pairs_train, pairs_val, labels_train, labels_val = train_test_split(\n",
    "    lfw.pairs, lfw.target, test_size=0.2, random_state=42, stratify=lfw.target\n",
    ")\n",
    "\n",
    "lfw_test = fetch_lfw_pairs(subset='test', resize=0.5, color=False)\n",
    "pairs_test, labels_test = lfw_test.pairs, lfw_test.target\n",
    "\n",
    "print(f\"Treino: {len(pairs_train)}, Validação: {len(pairs_val)}, Teste: {len(pairs_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad9d026",
   "metadata": {},
   "source": [
    "### Visualização dos Pares de Imagens\n",
    "\n",
    "Para compreender a natureza dos dados, visualizaremos alguns exemplos. Mostraremos um par positivo (duas imagens da mesma pessoa) e um par negativo (imagens de pessoas distintas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad41fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pair(pair, label):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    \n",
    "    axes[0].imshow(pair[0], cmap='gray')\n",
    "    axes[0].set_title('Image 1')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(pair[1], cmap='gray')\n",
    "    axes[1].set_title('Image 2')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    title = 'Same Person' if label == 1 else 'Different People'\n",
    "    fig.suptitle(title, fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "# Encontrar um exemplo de cada\n",
    "positive_idx = np.where(labels_train == 1)[0][0]\n",
    "negative_idx = np.where(labels_train == 0)[0][0]\n",
    "\n",
    "print(\"Exemplo de Par Positivo (Mesma Pessoa):\")\n",
    "show_pair(pairs_train[positive_idx], labels_train[positive_idx])\n",
    "\n",
    "print(\"Exemplo de Par Negativo (Pessoas Diferentes):\")\n",
    "show_pair(pairs_train[negative_idx], labels_train[negative_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2e7244",
   "metadata": {},
   "source": [
    "### Definição do Dataset PyTorch\n",
    "\n",
    "Para integrar os dados ao ecossistema PyTorch, criamos uma classe `Dataset` customizada. Esta classe encapsula a lógica de acesso aos pares de imagens e seus respectivos rótulos, além de aplicar as transformações necessárias (conversão para Tensor e normalização)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a946bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LFWPairedDataset(Dataset):\n",
    "    def __init__(self, pairs, labels, transform=None):\n",
    "        self.pairs = pairs\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img1 = np.expand_dims(self.pairs[idx][0], axis=-1)\n",
    "        img2 = np.expand_dims(self.pairs[idx][1], axis=-1)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "            \n",
    "        return img1, img2, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0550a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_aug = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((100, 100)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(10),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((100, 100)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = LFWPairedDataset(pairs_train, labels_train, transform=transform_aug)\n",
    "val_dataset   = LFWPairedDataset(pairs_val, labels_val, transform=transform)\n",
    "test_dataset  = LFWPairedDataset(pairs_test, labels_test, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73d6e3d",
   "metadata": {},
   "source": [
    "### A Arquitetura da Rede Siamesa\n",
    "\n",
    "Uma rede siamesa consiste em duas (ou mais) sub-redes idênticas que compartilham pesos (parâmetros). O objetivo desta sub-rede, que chamaremos de `BaseNetwork`, é extrair um vetor de características (embedding) da imagem de entrada.\n",
    "\n",
    "#### Rede Base (Feature Extractor)\n",
    "\n",
    "A `BaseNetwork` será uma Rede Neural Convolucional (CNN) relativamente simples. Ela processará a imagem de entrada e produzirá um vetor latente de dimensão fixa (ex: 128). A qualidade deste embedding é o que o modelo deve aprender: imagens da mesma pessoa devem resultar em embeddings próximos no espaço vetorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccda24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNetwork(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5, padding=2), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, padding=2), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 96, 3, padding=1), nn.BatchNorm2d(96), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(96 * 12 * 12, 256), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(256, embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return F.normalize(x, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4185219",
   "metadata": {},
   "source": [
    "#### Rede Siamesa Completa\n",
    "\n",
    "A `SiameseNetwork` propriamente dita instancia a `BaseNetwork` (uma única vez, garantindo o compartilhamento de pesos). Seu método `forward` aceita duas imagens de entrada, `input1` e `input2`, passa cada uma delas pela `BaseNetwork` e retorna os dois vetores de embedding resultantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a08a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.base_network = BaseNetwork(embedding_dim)\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.base_network(input1)\n",
    "        output2 = self.base_network(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2dab65",
   "metadata": {},
   "source": [
    "### Função de Custo: Contrastive Loss\n",
    "\n",
    "Para treinar uma rede siamesa, não utilizamos funções de custo de classificação tradicionais (como Cross-Entropy). Em vez disso, usamos uma função de custo baseada em distância, como a **Contrastive Loss**.\n",
    "\n",
    "O objetivo desta função é:\n",
    "1.  Se o par for da mesma classe (label $Y=1$), a distância Euclidiana $D_W$ entre seus embeddings ($E(X_1)$ e $E(X_2)$) deve ser minimizada.\n",
    "2.  Se o par for de classes diferentes (label $Y=0$), a distância $D_W$ deve ser maximizada, mas apenas até ultrapassar uma certa **margem** ($m$). Se a distância já for maior que a margem, a perda é zero (o modelo já separou bem o par).\n",
    "\n",
    "A distância Euclidiana é definida como:\n",
    "$$D_W = || E(X_1) - E(X_2) ||_2$$\n",
    "\n",
    "A Contrastive Loss é formulada como:\n",
    "$$L(W, (Y, X_1, X_2)) = Y \\cdot \\frac{1}{2} (D_W)^2 + (1 - Y) \\cdot \\frac{1}{2} \\{ \\max(0, m - D_W) \\}^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83259816",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # Distância euclidiana entre embeddings normalizados\n",
    "        dist = F.pairwise_distance(output1, output2)\n",
    "\n",
    "        # Perda para pares positivos (mesma classe)\n",
    "        pos_loss = label * torch.pow(dist, 2)\n",
    "\n",
    "        # Perda para pares negativos (classes diferentes)\n",
    "        neg_loss = (1 - label) * torch.pow(torch.clamp(self.margin - dist, min=0.0), 2)\n",
    "\n",
    "        # Média das perdas\n",
    "        loss = torch.mean(pos_loss + neg_loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad99b975",
   "metadata": {},
   "source": [
    "### Configuração do Treinamento\n",
    "\n",
    "Definimos os hiperparâmetros, instanciamos o modelo, a função de custo (Contrastive Loss) e o otimizador (Adam). Também configuramos o dispositivo de hardware (GPU, se disponível, ou CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações\n",
    "MARGIN = 1.4\n",
    "\n",
    "# Instanciação\n",
    "model = SiameseNetwork(embedding_dim=256).to(device)\n",
    "criterion = ContrastiveLoss(margin=MARGIN)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928c6c2b",
   "metadata": {},
   "source": [
    "### Loop de Treinamento e Validação\n",
    "\n",
    "Iteramos sobre as épocas de treinamento. Em cada época, primeiro executamos a fase de treinamento (`model.train()`), onde calculamos a perda, realizamos a retropropagação (backpropagation) e atualizamos os pesos. Em seguida, executamos a fase de validação (`model.eval()`), onde apenas calculamos a perda nos dados de validação (sem calcular gradientes) para monitorar a generalização do modelo e detectar overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649d5bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 25\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    \n",
    "    for i, (img1, img2, label) in enumerate(train_loader):\n",
    "        img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output1, output2 = model(img1, img2)\n",
    "        loss = criterion(output1, output2, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item()\n",
    "        \n",
    "    epoch_train_loss = running_train_loss / len(train_loader)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img1, img2, label in val_loader:\n",
    "            img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "\n",
    "            output1, output2 = model(img1, img2)\n",
    "            loss = criterion(output1, output2, label)\n",
    "            running_val_loss += loss.item()\n",
    "            \n",
    "    epoch_val_loss = running_val_loss / len(val_loader)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {epoch_train_loss:.4f} | Val Loss: {epoch_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000bf113",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Contrastive Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d5cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def compute_distances_and_labels(model, dataloader, device, mode=\"contrastive\"):\n",
    "    model.eval()\n",
    "    dists, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            if mode == \"contrastive\":\n",
    "                x1, x2, y = [x.to(device) for x in batch]\n",
    "                e1, e2 = model(x1, x2)\n",
    "                dist = F.pairwise_distance(e1, e2)\n",
    "                dists.extend(dist.cpu().numpy())\n",
    "                labels.extend(y.cpu().numpy())\n",
    "\n",
    "            elif mode == \"triplet\":\n",
    "                a, p, n = [x.to(device) for x in batch]\n",
    "                ea, ep, en = model(a), model(p), model(n)\n",
    "                d_pos = F.pairwise_distance(ea, ep)\n",
    "                d_neg = F.pairwise_distance(ea, en)\n",
    "                dists.extend(d_pos.cpu().numpy())\n",
    "                labels.extend(np.ones(len(d_pos)))\n",
    "                dists.extend(d_neg.cpu().numpy())\n",
    "                labels.extend(np.zeros(len(d_neg)))\n",
    "\n",
    "    return np.array(dists), np.array(labels)\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataloader, device, mode=\"contrastive\", title=\"ROC Curve\"):\n",
    "    dists, labels = compute_distances_and_labels(model, dataloader, device, mode)\n",
    "\n",
    "    fpr, tpr, thr = roc_curve(labels, -dists)\n",
    "    auc_val = auc(fpr, tpr)\n",
    "    best = np.argmax(tpr - fpr)\n",
    "    best_thr = -thr[best]\n",
    "    preds = (dists < best_thr).astype(int)\n",
    "    acc = (preds == labels).mean()\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC={auc_val:.3f}\")\n",
    "    plt.scatter(fpr[best], tpr[best], c='red', label=f\"thr={best_thr:.3f}\")\n",
    "    plt.plot([0,1],[0,1],'--',color='gray')\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"AUC: {auc_val:.3f}\")\n",
    "    print(f\"Melhor threshold: {best_thr:.3f}\")\n",
    "    print(f\"Acurácia: {acc*100:.2f}%\")\n",
    "    print(f\"Sensibilidade (TPR): {tpr[best]:.3f}\")\n",
    "    print(f\"Especificidade (1 - FPR): {1-fpr[best]:.3f}\")\n",
    "\n",
    "    return auc_val, acc, best_thr\n",
    "\n",
    "\n",
    "def test_model(model, dataloader, device, threshold, mode=\"contrastive\"):\n",
    "    dists, labels = compute_distances_and_labels(model, dataloader, device, mode)\n",
    "    preds = (dists < threshold).astype(int)\n",
    "    acc = (preds == labels).mean()\n",
    "    print(f\"Acurácia no teste (thr={threshold:.3f}): {acc*100:.2f}%\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816eeea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_val, acc_val, best_thr = evaluate_model(model, val_loader, device, mode=\"contrastive\")\n",
    "acc_test = test_model(model, test_loader, device, best_thr, mode=\"contrastive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7151bd18",
   "metadata": {},
   "source": [
    "### Inferência no Conjunto de Teste\n",
    "\n",
    "Para realizar a inferência, passamos pares de imagens do conjunto de teste pela rede (em modo `model.eval()`). Calculamos a distância Euclidiana entre os embeddings de saída. Um limiar (threshold) é usado para tomar a decisão: se a distância for menor que o limiar, o modelo prevê que são a mesma pessoa; caso contrário, prevê que são pessoas diferentes. Um limiar comum para iniciar é `margin / 2`, mas o ideal é que ele seja sintonizado usando o conjunto de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf1c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples_to_plot(dataloader, mode=\"contrastive\", num_pos=5, num_neg=5):\n",
    "    samples = []\n",
    "    for batch in dataloader:\n",
    "        if mode == \"contrastive\":\n",
    "            img1, img2, labels = batch\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i].item()\n",
    "                if label == 1.0 and len([s for s in samples if s[2] == 1.0]) < num_pos:\n",
    "                    samples.append((img1[i].cpu(), img2[i].cpu(), 1.0))\n",
    "                elif label == 0.0 and len([s for s in samples if s[2] == 0.0]) < num_neg:\n",
    "                    samples.append((img1[i].cpu(), img2[i].cpu(), 0.0))\n",
    "            if len(samples) >= num_pos + num_neg:\n",
    "                break\n",
    "\n",
    "        elif mode == \"triplet\":\n",
    "            anchor, positive, negative = batch\n",
    "            for i in range(min(num_pos, len(anchor))):\n",
    "                samples.append((anchor[i].cpu(), positive[i].cpu(), negative[i].cpu()))\n",
    "            if len(samples) >= num_pos:\n",
    "                break\n",
    "\n",
    "    print(f\"Total de samples coletados: {len(samples)}\")\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea34436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, text=None):\n",
    "    img = img * 0.5 + 0.5  # desnormaliza\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)).squeeze(), cmap='gray')\n",
    "    if text:\n",
    "        plt.title(text)\n",
    "    plt.axis('off')\n",
    "\n",
    "def show_inference_examples(model, samples, device, threshold, mode=\"contrastive\", max_examples=10):\n",
    "    model.eval()\n",
    "\n",
    "    for i, sample in enumerate(samples[:max_examples]):\n",
    "        if mode == \"contrastive\":\n",
    "            img1, img2, label = sample\n",
    "            with torch.no_grad():\n",
    "                d = F.pairwise_distance(*model(img1.unsqueeze(0).to(device),\n",
    "                                               img2.unsqueeze(0).to(device)))\n",
    "                distance = d.item()\n",
    "            pred = \"Same\" if distance < threshold else \"Different\"\n",
    "            truth = \"Same\" if label == 1.0 else \"Different\"\n",
    "\n",
    "            print(f\"\\nExemplo {i+1}\")\n",
    "            print(f\"Distância: {distance:.4f}\")\n",
    "            print(f\"Predição: {pred} (Limiar: {threshold:.2f})\")\n",
    "            print(f\"Verdadeiro: {truth}\")\n",
    "\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(5, 2.5))\n",
    "            for ax, img in zip(axes, [img1, img2]):\n",
    "                plt.sca(ax)\n",
    "                imshow(img)\n",
    "            plt.show()\n",
    "\n",
    "        elif mode == \"triplet\":\n",
    "            anchor, positive, negative = sample\n",
    "            with torch.no_grad():\n",
    "                ea, ep, en = model(anchor.unsqueeze(0).to(device)), \\\n",
    "                             model(positive.unsqueeze(0).to(device)), \\\n",
    "                             model(negative.unsqueeze(0).to(device))\n",
    "                d_pos = F.pairwise_distance(ea, ep).item()\n",
    "                d_neg = F.pairwise_distance(ea, en).item()\n",
    "\n",
    "            print(f\"\\nExemplo {i+1}\")\n",
    "            print(f\"Distância (âncora-positivo): {d_pos:.4f}\")\n",
    "            print(f\"Distância (âncora-negativo): {d_neg:.4f}\")\n",
    "            print(f\"Decisão: {'Correto' if d_pos < d_neg else 'Incorreto'} (Limiar: {threshold:.2f})\")\n",
    "\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(7, 2.5))\n",
    "            for ax, img, title in zip(axes, [anchor, positive, negative], [\"Âncora\", \"Positivo\", \"Negativo\"]):\n",
    "                plt.sca(ax)\n",
    "                imshow(img, text=title)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4282f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_to_plot = get_samples_to_plot(test_loader, mode=\"contrastive\", num_pos=5, num_neg=5)\n",
    "show_inference_examples(model, samples_to_plot, device, best_thr, mode=\"contrastive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96536963",
   "metadata": {},
   "source": [
    "# Triplet Loss\n",
    "\n",
    "Embora a Contrastive Loss funcione bem com pares de imagens, outra abordagem predominante no aprendizado de métricas (metric learning) é a **Triplet Loss** (Perda Tripla). Esta função de custo não opera em pares (positivo/negativo), mas em *tripletos* de amostras.\n",
    "\n",
    "Um tripleto consiste em:\n",
    "1.  **Âncora ($A$):** Uma imagem de referência (ex: um retrato de uma pessoa).\n",
    "2.  **Positivo ($P$):** Uma imagem diferente, mas da *mesma classe* que a âncora (ex: outro retrato da mesma pessoa).\n",
    "3.  **Negativo ($N$):** Uma imagem de uma classe *diferente* da âncora (ex: um retrato de uma pessoa diferente).\n",
    "\n",
    "O objetivo da Triplet Loss é modificar o espaço de embedding de forma que a distância entre a âncora e o positivo seja menor do que a distância entre a âncora e o negativo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489cb045",
   "metadata": {},
   "source": [
    "### Mineração de Tripletos (Triplet Mining)\n",
    "\n",
    "Um desafio central na utilização da Triplet Loss é a seleção de tripletos. Se selecionarmos tripletos aleatoriamente, muitos deles serão \"fáceis\" (onde $D(A, N)$ já é muito maior que $D(A, P) + m$), resultando em uma perda nula e nenhum aprendizado.\n",
    "\n",
    "Para um treinamento eficaz, é crucial empregar estratégias de \"mineração de tripletos\" (Triplet Mining):\n",
    "1.  **Hard Negative/Positive Mining:** Selecionar os exemplos positivos mais distantes ($D(A, P)$) e os exemplos negativos mais próximos ($D(A, N)$) dentro de um lote (batch).\n",
    "2.  **Semi-Hard Negative Mining:** Selecionar negativos que violam a margem ($D(A, P) < D(A, N) < D(A, P) + m$). Esta é uma abordagem muito comum, pois evita negativos excessivamente difíceis (colapsando o modelo) e ignora os negativos fáceis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727a85ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class LFWTripletDataset(Dataset):\n",
    "    def __init__(self, pairs, labels, transform=None):\n",
    "        self.transform = transform\n",
    "        self.same_pairs = [p for p, l in zip(pairs, labels) if l == 1]\n",
    "        self.diff_imgs = [img for p, l in zip(pairs, labels) if l == 0 for img in p]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.same_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Âncora e positivo vêm de um par positivo\n",
    "        anchor, positive = self.same_pairs[idx]\n",
    "        # Negativo vem de uma imagem de outro par (aleatório)\n",
    "        negative = random.choice(self.diff_imgs)\n",
    "\n",
    "        # Expande o canal (grayscale → [H,W,1])\n",
    "        anchor = np.expand_dims(anchor, -1)\n",
    "        positive = np.expand_dims(positive, -1)\n",
    "        negative = np.expand_dims(negative, -1)\n",
    "\n",
    "        # Aplica transformações\n",
    "        if self.transform:\n",
    "            anchor = self.transform(anchor)\n",
    "            positive = self.transform(positive)\n",
    "            negative = self.transform(negative)\n",
    "\n",
    "        return anchor, positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b0196",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_triplet_dataset = LFWTripletDataset(pairs_train, labels_train, transform=transform_aug)\n",
    "val_triplet_dataset   = LFWTripletDataset(pairs_val, labels_val, transform=transform)\n",
    "test_triplet_dataset  = LFWTripletDataset(pairs_test, labels_test, transform=transform)\n",
    "\n",
    "train_triplet_loader = DataLoader(train_triplet_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_triplet_loader   = DataLoader(val_triplet_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_triplet_loader  = DataLoader(test_triplet_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf37961",
   "metadata": {},
   "source": [
    "### Implementação da Triplet Loss\n",
    "\n",
    "O objetivo da Triplet Loss é garantir que a distância entre a Âncora ($A$) e o Positivo ($P$) seja menor que a distância entre a Âncora ($A$) e o Negativo ($N$), respeitando uma margem ($m$).\n",
    "\n",
    "A distância Euclidiana (L2) entre dois vetores $X_1$ e $X_2$ é:\n",
    "$$D(X_1, X_2) = || X_1 - X_2 ||_2$$\n",
    "\n",
    "A função de custo para um único tripleto é:\n",
    "$$L(A, P, N) = \\max(0, D(A, P) - D(A, N) + m)$$\n",
    "\n",
    "Para implementar isso em PyTorch, seguiremos três passos dentro da classe:\n",
    "1.  **Cálculo das Distâncias:** Usaremos `F.pairwise_distance` para calcular $D(A, P)$ e $D(A, N)$. Esta função calcula eficientemente a distância L2 (quando `p=2`) entre cada par de vetores em um lote.\n",
    "2.  **Aplicação da Fórmula:** Implementaremos a lógica $D(A, P) - D(A, N) + m$.\n",
    "3.  **Aplicação do Max(0, ...):** Usaremos `F.relu` para aplicar a função $\\max(0, \\cdot)$, que zera a perda para tripletos que já satisfazem a condição da margem.\n",
    "4.  **Média do Lote:** Por fim, calculamos a média (`torch.mean`) da perda sobre todos os tripletos no lote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b72dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        dist_pos = F.pairwise_distance(anchor, positive)\n",
    "        dist_neg = F.pairwise_distance(anchor, negative)\n",
    "        loss = F.relu(dist_pos.pow(2) - dist_neg.pow(2) + self.margin)\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa9f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_triplet = BaseNetwork(embedding_dim=256).to(device)\n",
    "criterion = TripletLoss(margin=1.0)\n",
    "optimizer = optim.AdamW(model_triplet.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb73d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 25\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model_triplet.train()\n",
    "    running_loss = 0\n",
    "    for a, p, n in train_triplet_loader:\n",
    "        a, p, n = a.to(device), p.to(device), n.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        emb_a, emb_p, emb_n = model_triplet(a), model_triplet(p), model_triplet(n)\n",
    "        loss = criterion(emb_a, emb_p, emb_n)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    model_triplet.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for a, p, n in val_triplet_loader:\n",
    "            a, p, n = a.to(device), p.to(device), n.to(device)\n",
    "            emb_a, emb_p, emb_n = model_triplet(a), model_triplet(p), model_triplet(n)\n",
    "            loss = criterion(emb_a, emb_p, emb_n)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_triplet_loader)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Train: {train_loss:.4f} | Val: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec684eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(train_losses, label=\"Train\")\n",
    "plt.plot(val_losses, label=\"Val\")\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.ylabel(\"Triplet Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b7e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_val, acc_val, best_triplet_thr = evaluate_model(model_triplet, val_triplet_loader, device, mode=\"triplet\")\n",
    "acc_test = test_model(model_triplet, test_triplet_loader, device, best_thr, mode=\"triplet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295ddd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_to_plot = get_samples_to_plot(test_triplet_loader, mode=\"triplet\", num_pos=2, num_neg=2)\n",
    "show_inference_examples(model_triplet, samples_to_plot, device, best_triplet_thr, mode=\"triplet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
