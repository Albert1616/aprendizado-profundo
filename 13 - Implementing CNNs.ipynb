{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7167f559",
   "metadata": {},
   "source": [
    "# Implementação e Treinamento de uma CNN\n",
    "\n",
    "Neste notebook, abordaremos o carregamento de datasets e a implementação de uma CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31344c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f845175",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8481ef59",
   "metadata": {},
   "source": [
    "### Carregamento e Pré-processamento do Dataset CIFAR-10\n",
    "\n",
    "O dataset CIFAR-10 é composto por 60.000 imagens coloridas de 32x32 pixels, distribuídas em 10 classes. Aplicaremos uma sequência de transformações (`transforms.Compose`):\n",
    "\n",
    "1.  **`transforms.ToTensor()`**: Converte as imagens para tensores do PyTorch.\n",
    "2.  **`transforms.Normalize()`**: Normaliza os tensores, escalando os valores dos pixels para o intervalo [-1, 1]. A equação de normalização para um canal de um pixel $x$ é:\n",
    "\n",
    "    $$x_{norm} = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "    Onde $\\mu$ é a média e $\\sigma$ é o desvio padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b1930",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Classes do CIFAR-10\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173828ac",
   "metadata": {},
   "source": [
    "### Visualização de Amostras de Dados\n",
    "\n",
    "É uma boa prática inspecionar visualmente algumas amostras do dataset para garantir que os dados foram carregados e processados corretamente. O código a seguir extrai um lote (*batch*) de imagens do `train_loader` e as exibe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c064fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # desnormalizar\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961e908b",
   "metadata": {},
   "source": [
    "### Definição da Arquitetura da CNN\n",
    "\n",
    "A arquitetura da CNN será definida utilizando `nn.Sequential` para agrupar camadas de forma modular. Dividiremos o modelo em duas partes principais:\n",
    "\n",
    "* **Extrator de Features (`features`)**: Um bloco sequencial contendo as camadas convolucionais (`Conv2d`), de ativação (`ReLU`) e de pooling (`MaxPool2d`), responsável por aprender e extrair características hierárquicas das imagens.\n",
    "* **Classificador (`classifier`)**: Um segundo bloco sequencial, que recebe o mapa de features achatado (*flattened*) e utiliza camadas totalmente conectadas (`Linear`) para realizar a classificação final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2a73fb",
   "metadata": {},
   "source": [
    "### Implementação\n",
    "\n",
    "Defina um modelo contendo 2 blocos, cada um contendo uma camada convolucional, uma função de ativação e um pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7caec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Bloco de extração de features\n",
    "        self.features = nn.Sequential(\n",
    "            # Seu código aqui\n",
    "        )\n",
    "        \n",
    "        # Bloco classificador\n",
    "        self.classifier = nn.Sequential(\n",
    "            # Seu código aqui\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Passa pelo extrator de features\n",
    "        \n",
    "        # Achata a saída para o classificador\n",
    "        \n",
    "        # Passa pelo classificador\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = SequentialCNN()\n",
    "\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "out = model(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc021a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SequentialCNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133af287",
   "metadata": {},
   "source": [
    "### Definição da Função de Perda e do Otimizador\n",
    "\n",
    "Para o treinamento, utilizaremos a função de perda de **Entropia Cruzada** (`nn.CrossEntropyLoss`), adequada para problemas de classificação multiclasse. Como otimizador, empregaremos o **Adam** (`optim.Adam`), um algoritmo de otimização adaptativo eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbe0b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878cdfb8",
   "metadata": {},
   "source": [
    "### Treinamento do Modelo\n",
    "\n",
    "O loop de treinamento itera sobre o dataset por um número definido de épocas. Em cada iteração, realiza o *forward pass*, calcula a perda, executa o *backward pass* para computar os gradientes (backpropagation) e utiliza o otimizador para atualizar os pesos da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5bad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # --- Treinamento ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # --- Validação ---\n",
    "    model.eval()  # Coloca o modelo em modo de avaliação\n",
    "    running_loss_val = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            running_loss_val += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = running_loss_val / len(test_loader)\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}] -> Train Loss: {train_loss:.3f}, Train Acc: {train_accuracy:.2f}% | Val Loss: {val_loss:.3f}, Val Acc: {val_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fdb0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), train_accuracies, label='Training Accuracy')\n",
    "plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e7d584",
   "metadata": {},
   "source": [
    "### Avaliação do Modelo\n",
    "\n",
    "Após o treinamento, avaliamos a performance do modelo no conjunto de teste. O cálculo de gradientes é desativado com `torch.no_grad()` para otimizar o processo, uma vez que não há necessidade de retropropagação durante a inferência. A acurácia é calculada comparando as previsões do modelo com os rótulos verdadeiros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c12aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f49e67",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec84a7e",
   "metadata": {},
   "source": [
    "### Exercício 1\n",
    "\n",
    "O modelo está muito simples para o problema. Aumente o número de canais nas camadas convolucionais. Além disso, adicione Batch Normalization após as camadas convolucionais e Dropout após as camadas lineares no modelo. Compare com a implementação original."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bddc654",
   "metadata": {},
   "source": [
    "### Exercício 2\n",
    "\n",
    "Experimente diferentes combinações para o número de filtros nas duas camadas convolucionais. Avalie todas as combinações possíveis e identifique o modelo que obtiver o melhor desempenho no conjunto de validação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd3953b",
   "metadata": {},
   "source": [
    "### Exercício 3\n",
    "\n",
    "Explore diferentes configurações escolhidas aleatoriamente para o número de filtros nas camadas convolucionais e dos neurônios nas camadas lineares. Treine e avalie N configurações, registrando o desempenho em validação. Identifique o modelo com os melhores resultados entre as amostras testadas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
