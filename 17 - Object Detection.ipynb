{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29080652",
   "metadata": {},
   "source": [
    "# Detecção de Objetos\n",
    "\n",
    "Este notebook introduz os conceitos fundamentais da detecção de objetos, uma tarefa de visão computacional que envolve identificar e localizar múltiplos objetos dentro de uma imagem. Abordaremos uma implementação inspirada na arquitetura YOLO (You Only Look Once), focando na criação de um modelo capaz de prever caixas delimitadoras (bounding boxes) e classes para objetos. Para simplificar o problema e focar nos mecanismos centrais, construiremos um conjunto de dados sintético usando dígitos do MNIST, onde cada imagem conterá três dígitos em posições aleatórias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439bebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbf3c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b3737b",
   "metadata": {},
   "source": [
    "## Geração do Dataset Sintético\n",
    "\n",
    "Para treinar um modelo de detecção de objetos, precisamos de um conjunto de dados que forneça não apenas as imagens, mas também as caixas delimitadoras (bounding boxes) e as classes para cada objeto. A classe `ObjectsMNIST` implementa um `Dataset` customizado do PyTorch para gerar dados sintéticos em tempo real.\n",
    "\n",
    "Esta abordagem é mais robusta que a anterior:\n",
    "1.  Utiliza a biblioteca `PIL` (Pillow) para criar a tela (`canvas`) e colar os dígitos.\n",
    "2.  Aplica transformações de data augmentation mais realistas em cada dígito antes de colá-lo: uma leve variação de escala (`random.uniform(0.9, 1.3)`) e uma rotação (`random.uniform(-10, 10)`).\n",
    "3.  Implementa um mecanismo de anticolisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ad822",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectsMNIST(Dataset):\n",
    "    def __init__(self, root=\"./data\", split=\"train\", n_samples=5000, img_size=96, n_digits=3, iou_thr=0.15, max_tries=50):\n",
    "        self.n_samples, self.img_size, self.n_digits = n_samples, img_size, n_digits\n",
    "        self.iou_thr, self.max_tries = iou_thr, max_tries\n",
    "        base = datasets.MNIST(root=root, train=(split==\"train\"), download=True)\n",
    "        self.images, self.labels = base.data.numpy(), base.targets.numpy()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def _iou(self, a, b):\n",
    "        # a,b = (cx,cy,w,h) normalizados\n",
    "        xa1, ya1, xa2, ya2 = a[0]-a[2]/2, a[1]-a[3]/2, a[0]+a[2]/2, a[1]+a[3]/2\n",
    "        xb1, yb1, xb2, yb2 = b[0]-b[2]/2, b[1]-b[3]/2, b[0]+b[2]/2, b[1]+b[3]/2\n",
    "        inter = max(0, min(xa2, xb2)-max(xa1, xb1)) * max(0, min(ya2, yb2)-max(ya1, yb1))\n",
    "        area_a, area_b = (xa2-xa1)*(ya2-ya1), (xb2-xb1)*(yb2-yb1)\n",
    "        return inter / (area_a + area_b - inter + 1e-9)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        canvas = Image.new(\"L\", (self.img_size, self.img_size), 0)\n",
    "        ids = np.random.choice(len(self.images), self.n_digits, replace=False)\n",
    "        targets, boxes = [], []\n",
    "\n",
    "        for i in ids:\n",
    "            # pequena escala e rotação\n",
    "            img = Image.fromarray(self.images[i])\n",
    "            s = int(28 * random.uniform(0.9, 1.3))\n",
    "            img = img.resize((s, s), Image.BILINEAR)\n",
    "            if random.random() < 0.4:\n",
    "                img = img.rotate(random.uniform(-10, 10), expand=True, fillcolor=0)\n",
    "\n",
    "            # tenta colocar sem sobreposição\n",
    "            for _ in range(self.max_tries):\n",
    "                x, y = random.randint(0, self.img_size - img.width), random.randint(0, self.img_size - img.height)\n",
    "                box = ((x + img.width/2)/self.img_size, (y + img.height/2)/self.img_size,\n",
    "                       img.width/self.img_size, img.height/self.img_size)\n",
    "                if all(self._iou(box, b) < self.iou_thr for b in boxes):\n",
    "                    canvas.paste(img, (x, y))\n",
    "                    boxes.append(box)\n",
    "                    targets.append((int(self.labels[i]), *box))\n",
    "                    break\n",
    "\n",
    "        x = transforms.ToTensor()(canvas)\n",
    "        y = torch.tensor(targets, dtype=torch.float32)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49e16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = ObjectsMNIST(split=\"train\", n_samples=10000, img_size=IMG_SIZE, n_digits=3)\n",
    "test_dataset  = ObjectsMNIST(split=\"test\", n_samples=1000, img_size=IMG_SIZE, n_digits=3)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae1e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset_examples(dataset, n=8, cols=4, figsize_scale=3.0):\n",
    "    assert n > 0 and cols > 0\n",
    "    rows = int(np.ceil(n / cols))\n",
    "    img_size = getattr(dataset, \"img_size\", None)\n",
    "    \n",
    "    # Seleciona índices aleatórios sem criar DataLoader\n",
    "    idxs = random.sample(range(len(dataset)), k=n if n < len(dataset) else len(dataset))\n",
    "    plt.figure(figsize=(figsize_scale*cols, figsize_scale*rows))\n",
    "\n",
    "    for p, idx in enumerate(idxs, start=1):\n",
    "        img_t, targets = dataset[idx]                     # img_t: [1,H,W], targets: [K,5]\n",
    "        img_np = img_t.squeeze(0).numpy()                 # [H,W] para imshow\n",
    "        H, W = img_np.shape\n",
    "        if img_size is None:  # se não existir atributo, infere da imagem\n",
    "            img_size = max(H, W)\n",
    "\n",
    "        ax = plt.subplot(rows, cols, p)\n",
    "        ax.imshow(img_np, cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        # Desenha as caixas ground truth\n",
    "        for row in targets.tolist():\n",
    "            cls, cx, cy, w, h = row\n",
    "            # converte para pixels\n",
    "            x1 = (cx - w/2) * W\n",
    "            y1 = (cy - h/2) * H\n",
    "            ww = w * W\n",
    "            hh = h * H\n",
    "            rect = patches.Rectangle((x1, y1), ww, hh, linewidth=1.5, edgecolor='g', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(x1, y1 - 2, f\"{int(cls)}\", color='g', fontsize=8, va=\"bottom\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_dataset_examples(train_dataset, n=8, cols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e79052",
   "metadata": {},
   "source": [
    "## Arquitetura do Modelo\n",
    "\n",
    "Esta célula define uma arquitetura de rede neural convolucional (CNN) totalmente convolucional, inspirada no design do YOLO. A arquitetura é construída usando uma função auxiliar `block(cin, cout)` que atua como a unidade fundamental de downsampling. Este bloco contém uma `nn.Conv2d` com `stride=2` (que reduz a dimensão espacial pela metade), seguida por `nn.BatchNorm2d` para estabilização e uma ativação `nn.ReLU`.\n",
    "\n",
    "O `self.backbone` é um `nn.Sequential` que empilha quatro desses blocos, reduzindo a dimensão espacial da entrada (ex: 96x96) sequencialmente (96 -> 48 -> 24 -> 12 -> 6). A saída do backbone será um mapa de características com `S=6`. O `self.head` é uma única camada `nn.Conv2d` com kernel `1x1` que atua como o preditor, mapeando os canais de características (128) para o tensor de predição final com `1+4+C` canais, correspondendo ao score de objectness (1), às coordenadas da caixa (4) e aos logits de classe (C). O método `forward` conclui permutando a saída para o formato `[B, S, S, 1+4+C]`, facilitando o cálculo da perda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36561a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniYOLO(nn.Module):\n",
    "    def __init__(self, S, C):\n",
    "        super().__init__()\n",
    "        self.S, self.C = S, C\n",
    "        def block(cin, cout): \n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(cin, cout, 3, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(cout),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        self.backbone = nn.Sequential(\n",
    "            block(1, 32),   # 128 -> 64\n",
    "            block(32, 64),  # 64 -> 32\n",
    "            block(64, 128), # 32 -> 16\n",
    "            block(128, 128) # 16 -> 8\n",
    "        )\n",
    "        self.head = nn.Conv2d(128, 1+4+C, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.backbone(x)                 # [B,128,S,S]\n",
    "        y = self.head(f).permute(0,2,3,1)    # [B,S,S,1+4+C]\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b52c459",
   "metadata": {},
   "source": [
    "## Função de Perda\n",
    "\n",
    "Implementamos uma `nn.Module` customizada para a função de perda, pois ela é composta por múltiplos termos tratados de forma diferente. Esta implementação eficiente da perda YOLO é a soma ponderada de três componentes.\n",
    "\n",
    "O primeiro é a **Perda de Confiança (Objectness Loss)**, que utiliza `BCEWithLogitsLoss` para comparar a predição de objectness (`obj_p`) com o alvo (`obj_t`). Esta perda é calculada sobre *todas* as células da grade, penalizando tanto falsos positivos quanto falsos negativos.\n",
    "\n",
    "Os outros dois componentes são aplicados seletivamente. A **Perda de Localização (Box Loss)** usa `L1Loss` para regredir as coordenadas da caixa. A **Perda de Classificação (Class Loss)** usa `CrossEntropyLoss` para a classe. Crucialmente, ambas as perdas (box e class) são calculadas *apenas* nas células onde um objeto está realmente presente. Isso é alcançado através de uma `mask` booleana (`obj_t > 0.5`) que filtra apenas as predições e alvos relevantes.\n",
    "\n",
    "A perda final é `obj_loss + self.lb*box_loss + self.lc*cls_loss`, onde `lb` e `lc` ponderam a importância relativa da localização e classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcdcf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLoss(nn.Module):\n",
    "    def __init__(self, lambda_box=5.0, lambda_cls=1.0):\n",
    "        super().__init__()\n",
    "        self.lb, self.lc = lambda_box, lambda_cls\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "        self.ce  = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        obj_t = target[..., 0]         # [B,S,S]\n",
    "        box_t = target[..., 1:5]       # [B,S,S,4]\n",
    "        cls_t = torch.argmax(target[..., 5:], dim=-1)  # [B,S,S]\n",
    "\n",
    "        obj_p = pred[..., 0]\n",
    "        box_p = pred[..., 1:5]\n",
    "        cls_p = pred[..., 5:]\n",
    "\n",
    "        obj_loss = self.bce(obj_p, obj_t).mean()\n",
    "\n",
    "        mask = (obj_t > 0.5).unsqueeze(-1)  # [B,S,S,1]\n",
    "        if mask.any():\n",
    "            box_loss = F.l1_loss(box_p[mask.expand_as(box_p)], box_t[mask.expand_as(box_t)], reduction=\"mean\")\n",
    "            cls_loss = self.ce(cls_p[obj_t>0.5], cls_t[obj_t>0.5]).mean()\n",
    "        else:\n",
    "            box_loss = torch.tensor(0., device=pred.device)\n",
    "            cls_loss = torch.tensor(0., device=pred.device)\n",
    "\n",
    "        return obj_loss + self.lb*box_loss + self.lc*cls_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73668464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "S = 8\n",
    "C = 10\n",
    "model = MiniYOLO(S=S, C=C).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss e otimizador\n",
    "criterion = YoloLoss(lambda_box=5.0, lambda_cls=1.0)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7e0695",
   "metadata": {},
   "source": [
    "## Construção dos Alvos\n",
    "\n",
    "O modelo produz uma grade `[B, S, S, 1+4+C]`, mas o `Dataset` fornece uma lista de tensores `[K_i, 5]`. A função `build_targets` é uma etapa de pré-processamento essencial que converte o formato do \"ground-truth\" do dataset para o formato de grade exigido pela função de perda.\n",
    "\n",
    "Para cada imagem no lote, a função itera sobre seus objetos \"ground-truth\" e determina a célula da grade `(i, j)` responsável por cada objeto, com base no seu centro `(cx, cy)`. Um mecanismo de **Tratamento de Colisão** é implementado: se múltiplos objetos forem mapeados para a mesma célula `(i, j)`, a estratégia é manter apenas o objeto com a maior área (`w*h`).\n",
    "\n",
    "Além disso, a função aplica uma **Transformação de Coordenadas**, uma técnica comum em implementações YOLO. O alvo não armazena `(cx, cy, w, h)` diretamente, mas sim valores transformados que são mais fáceis para a rede regredir. As coordenadas `tx, ty` são calculadas como a posição do centro relativa ao canto da célula (`cx*S - i`), e as dimensões `tw, th` são armazenadas no espaço logarítmico (`math.log(w*S)`). O tensor `T` na posição `[b, j, i]` é então preenchido com o vetor final: `[1.0 (objectness), tx, ty, tw, th, ...one-hot class...]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bba67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_targets(batch_targets, S, C):\n",
    "    B = len(batch_targets)\n",
    "    T = torch.zeros(B, S, S, 1+4+C)\n",
    "\n",
    "    for b, targets in enumerate(batch_targets):\n",
    "        if targets.numel() == 0:\n",
    "            continue\n",
    "\n",
    "        # Mantém a melhor box por célula (maior área)\n",
    "        best = {}\n",
    "\n",
    "        for cls, cx, cy, w, h in targets:\n",
    "            i = int((cx * S).clamp(0, S-1).floor())\n",
    "            j = int((cy * S).clamp(0, S-1).floor())\n",
    "            area = w*h\n",
    "\n",
    "            if (j,i) in best and area <= best[(j,i)][0]:\n",
    "                continue\n",
    "\n",
    "            tx, ty = cx*S - i, cy*S - j\n",
    "            tw, th = torch.log(w*S + 1e-6), torch.log(h*S + 1e-6)\n",
    "\n",
    "            vec = torch.zeros(1+4+C)\n",
    "            vec[0] = 1\n",
    "            vec[1:5] = torch.tensor([tx, ty, tw, th])\n",
    "            vec[5 + int(cls)] = 1\n",
    "\n",
    "            best[(j,i)] = (area, vec)\n",
    "\n",
    "        for (j,i), (_, vec) in best.items():\n",
    "            T[b, j, i] = vec\n",
    "\n",
    "    return T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71befca5",
   "metadata": {},
   "source": [
    "## Loop de Treinamento\n",
    "\n",
    "O treinamento é encapsulado na função `run_epoch`, que executa uma época completa de treinamento ou validação. A função recebe um `loader` e um booleano `train` que alterna o modelo entre os modos `train` e `eval` usando `model.train(mode=train)`.\n",
    "\n",
    "Dentro do loop do lote, a etapa crítica é a chamada `T = build_targets(...)`, que converte os alvos `t` (vindos do `DataLoader`) para o tensor de grade `T` esperado pela função de perda (`criterion`). O cálculo do `forward pass` e da perda é envolvido em um contexto `torch.set_grad_enabled(train)`, que habilita o cálculo de gradientes apenas durante o treinamento. Se `train` for verdadeiro, o `backward pass` e a atualização do otimizador são executados. O loop principal itera pelo número de `EPOCHS`, chamando `run_epoch` para os dados de treino e teste e imprimindo as perdas resultantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea11fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "EPOCHS = 4\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train(mode=train)\n",
    "    total = 0.0\n",
    "    for x, t in loader:\n",
    "        x = x.to(device)\n",
    "        T = build_targets([y for y in t], S, C).to(device)\n",
    "        with torch.set_grad_enabled(train):\n",
    "            y = model(x)\n",
    "            loss = criterion(y, T)\n",
    "            if train:\n",
    "                optim.zero_grad(); loss.backward(); optim.step()\n",
    "        total += loss.item() * x.size(0)\n",
    "    return total / len(loader.dataset)\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    tr = run_epoch(train_loader, train=True)\n",
    "    va = run_epoch(test_loader, train=False)\n",
    "    print(f\"epoch {ep:02d} | train {tr:.4f} | val {va:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35b0cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o modelo treinado\n",
    "torch.save(model.state_dict(), \"miniyolo_mnist.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf55a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o modelo treinado\n",
    "model = MiniYOLO(S=S, C=C).to(device)\n",
    "model.load_state_dict(torch.load(\"miniyolo_mnist.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b985928e",
   "metadata": {},
   "source": [
    "## Inferência e Visualização dos Resultados\n",
    "\n",
    "Para avaliar visualmente o modelo, precisamos decodificar o tensor de saída bruto da rede `[S, S, 1+4+C]` em uma lista de caixas delimitadoras legíveis.\n",
    "\n",
    "A função `decode_boxes` é responsável por essa decodificação, revertendo o processo de `build_targets`. Ela itera por cada célula `(j, i)` da grade, aplica `sigmoid` na confiança e `softmax` nas classes, e filtra as células com confiança abaixo de um limiar `conf`. Para as células retidas, ela reverte as transformações de coordenadas: `tx` é convertido de volta para `cx` (coordenada relativa à imagem) usando `(i + torch.sigmoid(tx)) / S`, e `tw` é convertido de volta para `w` usando `torch.exp(tw) / S`. O score final é calculado como `P(Object) * P(Class | Object)`.\n",
    "\n",
    "A função `show_samples` utiliza a `decode_boxes` para a visualização. Ela obtém um lote de teste, executa o modelo e, para cada imagem, desenha tanto as caixas \"ground-truth\" (em verde) quanto as caixas previstas pela `decode_boxes` (em vermelho), anotadas com a classe e o score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6290417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_boxes(cell_pred, S, conf=0.4):\n",
    "    obj = torch.sigmoid(cell_pred[..., 0])\n",
    "    box = cell_pred[..., 1:5]\n",
    "    cls = F.softmax(cell_pred[..., 5:], dim=-1)\n",
    "    out = []\n",
    "    for j in range(S):\n",
    "        for i in range(S):\n",
    "            if obj[j,i] < conf: \n",
    "                continue\n",
    "            tx, ty, tw, th = box[j,i]\n",
    "            cx = (i + torch.sigmoid(tx)) / S\n",
    "            cy = (j + torch.sigmoid(ty)) / S\n",
    "            w  = torch.exp(tw) / S\n",
    "            h  = torch.exp(th) / S\n",
    "            c  = int(torch.argmax(cls[j,i]).item())\n",
    "            s  = float(obj[j,i] * cls[j,i,c])\n",
    "            out.append((s, c, float(cx), float(cy), float(w), float(h)))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b9e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(n=6, conf=0.5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, t = next(iter(test_loader))\n",
    "        x = x.to(device)\n",
    "        y = model(x).cpu()\n",
    "        imgs = x.cpu().numpy()\n",
    "        k = min(n, x.size(0))\n",
    "\n",
    "    plt.figure(figsize=(3*k, 3))\n",
    "    for idx in range(k):\n",
    "        ax = plt.subplot(1, k, idx+1)\n",
    "        ax.imshow(imgs[idx,0], cmap=\"gray\"); ax.axis(\"off\")\n",
    "        # GT\n",
    "        for lab, cx, cy, w, h in t[idx].tolist():\n",
    "            x1, y1 = (cx-w/2)*IMG_SIZE, (cy-h/2)*IMG_SIZE\n",
    "            rect = plt.Rectangle((x1,y1), w*IMG_SIZE, h*IMG_SIZE, fill=False, ec=\"g\", lw=1.5)\n",
    "            ax.add_patch(rect); ax.text(x1, y1-2, f\"gt:{int(lab)}\", color=\"g\", fontsize=8)\n",
    "        # Pred\n",
    "        boxes = decode_boxes(y[idx], S=S, conf=conf)\n",
    "        for sc, cl, cx, cy, w, h in boxes:\n",
    "            x1, y1 = (cx-w/2)*IMG_SIZE, (cy-h/2)*IMG_SIZE\n",
    "            rect = plt.Rectangle((x1,y1), w*IMG_SIZE, h*IMG_SIZE, fill=False, ec=\"r\", lw=1.5)\n",
    "            ax.add_patch(rect); ax.text(x1, y1-2, f\"p:{cl}@{sc:.2f}\", color=\"r\", fontsize=8)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "show_samples(n=4, conf=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
