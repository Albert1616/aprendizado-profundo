{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cf78b4e9",
      "metadata": {
        "id": "cf78b4e9"
      },
      "source": [
        "# Atividade: CNNs para Classificação\n",
        "\n",
        "Neste notebook, iremos preparar nosso próprio dataset e treinar um modelo de classificação de imagens."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "108587c0",
      "metadata": {
        "id": "108587c0"
      },
      "source": [
        "## Preparando os dados\n",
        "\n",
        "Os dados desta atividade serão baixados da internet. Utilizaremos para isso buscadores comuns. Em seguida, dividiremos em treinamento e validação."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install icrawler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLq6VNIcCrpb",
        "outputId": "366edf56-ad15-4df5-bf95-ec69a136a1df"
      },
      "id": "cLq6VNIcCrpb",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting icrawler\n",
            "  Downloading icrawler-0.6.10-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from icrawler) (4.13.5)\n",
            "Collecting bs4 (from icrawler)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from icrawler) (6.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from icrawler) (11.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from icrawler) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from icrawler) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from icrawler) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->icrawler) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->icrawler) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->icrawler) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->icrawler) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->icrawler) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->icrawler) (2025.11.12)\n",
            "Downloading icrawler-0.6.10-py3-none-any.whl (36 kB)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4, icrawler\n",
            "Successfully installed bs4-0.0.2 icrawler-0.6.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zel1urhDywa",
        "outputId": "ff06a155-17cf-443c-a990-dbe7266489b6"
      },
      "id": "_zel1urhDywa",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "7b74ce50",
      "metadata": {
        "id": "7b74ce50"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from icrawler.builtin import GoogleImageCrawler, BingImageCrawler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b98d4ebb",
      "metadata": {
        "id": "b98d4ebb"
      },
      "source": [
        "### Adquirindo as Imagens\n",
        "\n",
        "Utilizaremos o iCrawler para baixar imagens em buscadores através de termos especificados. Defina sua lista de classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bb2c5e01",
      "metadata": {
        "id": "bb2c5e01"
      },
      "outputs": [],
      "source": [
        "def download_images(keyword, folder, n_total=100):\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    downloaded = len(os.listdir(folder))\n",
        "    remaining = n_total - downloaded\n",
        "\n",
        "    while downloaded < n_total:\n",
        "        crawler = BingImageCrawler(storage={'root_dir': folder})\n",
        "        crawler.crawl(keyword=keyword, max_num=remaining, file_idx_offset=downloaded)\n",
        "        downloaded = len(os.listdir(folder))\n",
        "        remaining = n_total - downloaded\n",
        "        print(f\"Downloaded {downloaded}/{n_total}\")\n",
        "\n",
        "    print(\"Download complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "4008f42c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4008f42c",
        "outputId": "a537648d-3fbd-4c7a-96fe-2bd036622034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete!\n",
            "Downloaded 24/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:downloader:Response status code 403, file https://i.redd.it/me-as-a-baby-mestre-ensinador-v0-9ymnnd51tj6a1.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 49/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:downloader:Response status code 403, file https://i.redd.it/me-as-a-baby-mestre-ensinador-v0-9ymnnd51tj6a1.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 73/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:downloader:Response status code 403, file https://i.redd.it/me-as-a-baby-mestre-ensinador-v0-9ymnnd51tj6a1.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 97/100\n",
            "Downloaded 100/100\n",
            "Download complete!\n",
            "Downloaded 28/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:downloader:Response status code 403, file https://rare-gallery.com/fullwalls/14217-Luke-Skywalker.jpg\n",
            "ERROR:downloader:Response status code 403, file https://rare-gallery.com/uploads/posts/199742-luke-skywalker-2500x1673.jpg\n",
            "ERROR:downloader:Response status code 403, file https://preview.redd.it/luke-skywalker-v0-f9532tisvf0a1.jpg\n",
            "ERROR:downloader:Response status code 403, file https://preview.redd.it/luke-skywalker-v0-780x6yzh3u8b1.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 74/100\n",
            "Downloaded 100/100\n",
            "Download complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:downloader:Response status code 400, file https://media.istockphoto.com/id/864742274/photo/stormtrooper-portrait.jpg\n",
            "ERROR:downloader:Response status code 403, file https://oyster.ignimgs.com/mediawiki/apis.ign.com/star-wars-episode-7/thumb/b/b9/Stormtrooper.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 41/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:downloader:Response status code 400, file https://media.istockphoto.com/id/864742274/photo/stormtrooper-portrait.jpg\n",
            "ERROR:downloader:Response status code 403, file https://oyster.ignimgs.com/mediawiki/apis.ign.com/star-wars-episode-7/thumb/b/b9/Stormtrooper.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 82/100\n",
            "Downloaded 100/100\n",
            "Download complete!\n"
          ]
        }
      ],
      "source": [
        "search_terms = {\n",
        "    \"vader\": \"darth vader\", # nome da classe: termo que será usado na busca\n",
        "    \"yoda\": \"mestre yoda\",\n",
        "    \"luke\": \"luke skywalker\",\n",
        "    \"stormtrooper\": \"stormtrooper\"\n",
        "}\n",
        "\n",
        "for label, term in search_terms.items():\n",
        "    download_images(term, f\"data/star_wars/{label}\", n_total=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "roqx9umZDk90"
      },
      "id": "roqx9umZDk90",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0d931e35",
      "metadata": {
        "id": "0d931e35"
      },
      "source": [
        "### Treinamento e Validação\n",
        "\n",
        "Dividiremos as imagens baixadas nas pastas `train` e `val`. Defina uma porcentagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "88181559",
      "metadata": {
        "id": "88181559"
      },
      "outputs": [],
      "source": [
        "def split_train_val(root_dir, train_ratio=0.7, seed=42):\n",
        "    random.seed(seed)\n",
        "\n",
        "    train_dir = root_dir + \"_split/train\"\n",
        "    val_dir = root_dir + \"_split/val\"\n",
        "\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "    for class_name in os.listdir(root_dir):\n",
        "        class_path = os.path.join(root_dir, class_name)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "\n",
        "        images = [os.path.join(class_path, f) for f in os.listdir(class_path)]\n",
        "        images = [f for f in images if os.path.isfile(f)]\n",
        "        random.shuffle(images)\n",
        "\n",
        "        n_train = int(len(images) * train_ratio)\n",
        "\n",
        "        train_class_dir = os.path.join(train_dir, class_name)\n",
        "        val_class_dir = os.path.join(val_dir, class_name)\n",
        "        os.makedirs(train_class_dir, exist_ok=True)\n",
        "        os.makedirs(val_class_dir, exist_ok=True)\n",
        "\n",
        "        for img in images[:n_train]:\n",
        "            shutil.copy(img, os.path.join(train_class_dir, os.path.basename(img)))\n",
        "        for img in images[n_train:]:\n",
        "            shutil.copy(img, os.path.join(val_class_dir, os.path.basename(img)))\n",
        "\n",
        "        print(f\"{class_name}: {n_train} train, {len(images)-n_train} val\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_train_val(\"data/star_wars\", train_ratio=0.7, seed=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCCTdUOVHftn",
        "outputId": "2915df93-2f3c-4945-f29c-106b72250b36"
      },
      "id": "UCCTdUOVHftn",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yoda: 70 train, 30 val\n",
            "stormtrooper: 70 train, 30 val\n",
            "vader: 70 train, 30 val\n",
            "luke: 70 train, 30 val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9974e910",
      "metadata": {
        "id": "9974e910"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Implemente um Dataset PyTorch que carregue as imagens baixadas com suas respectivas classes. Aplique data augmentation e carregue em batches."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "wehEsGz7PnFz"
      },
      "id": "wehEsGz7PnFz",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "f91b901e",
      "metadata": {
        "id": "f91b901e"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/data/star_wars_split\"\n",
        "\n",
        "dataset_train = datasets.ImageFolder(\n",
        "    root=dataset_path + \"/train\",\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "dataset_val = datasets.ImageFolder(\n",
        "    root=dataset_path + \"/val\",\n",
        "    transform=val_transform\n",
        ")\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "dataloader_val = DataLoader(\n",
        "    dataset_val,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(dataloader_train))\n",
        "print(\"Treino:\", images.shape, labels)\n",
        "\n",
        "images, labels = next(iter(dataloader_val))\n",
        "print(\"Validação:\", images.shape, labels)\n"
      ],
      "metadata": {
        "id": "LWe6Pp2uRnw0",
        "outputId": "56200b1a-7b9e-4ad3-f149-860b266085f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LWe6Pp2uRnw0",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treino: torch.Size([16, 3, 224, 224]) tensor([0, 2, 3, 2, 1, 0, 2, 3, 1, 2, 0, 1, 0, 3, 0, 2])\n",
            "Validação: torch.Size([16, 3, 224, 224]) tensor([2, 2, 3, 2, 3, 2, 3, 3, 1, 2, 3, 3, 2, 1, 0, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83ab6c9e",
      "metadata": {
        "id": "83ab6c9e"
      },
      "source": [
        "## Definição do Modelo\n",
        "\n",
        "Defina aqui o modelo que será utilizado, sendo implementação própria ou um modelo pré-treinado. Teste diversas arquiteturas diferentes e verifique qual delas tem melhor desempenho em validação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "f7634074",
      "metadata": {
        "id": "f7634074"
      },
      "outputs": [],
      "source": [
        "Model = nn.Sequential(\n",
        "    # entrada com 3 canais (RGB)\n",
        "    nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "\n",
        "    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "\n",
        "    nn.MaxPool2d(2, 2),   # 224 → 112\n",
        "\n",
        "    nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "\n",
        "    nn.MaxPool2d(2, 2),   # 112 → 56\n",
        "\n",
        "    nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "\n",
        "    nn.MaxPool2d(2, 2),   # 56 → 28\n",
        "\n",
        "    nn.Flatten(),  # (batch, 256 * 28 * 28)\n",
        "\n",
        "    nn.Linear(256 * 28 * 28, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "\n",
        "    nn.Linear(512, 4)  # classes: luke, stormtrooper, vader, yoda\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dabbee06",
      "metadata": {
        "id": "dabbee06"
      },
      "source": [
        "## Treinamento\n",
        "\n",
        "Defina a função de custo e o otimizador do modelo. Em seguida, implemente o código de treinamento e treine-o. Ao final, exiba as curvas de treinamento e validação para a loss e a acurácia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d247d1dd",
      "metadata": {
        "id": "d247d1dd"
      },
      "outputs": [],
      "source": [
        "# Seu código aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85323b96",
      "metadata": {
        "id": "85323b96"
      },
      "source": [
        "## Inferência\n",
        "\n",
        "Calcule algumas métricas como acurácia, matriz de confusão, etc. Em seguida, teste o modelo em novas imagens das classes correspondentes mas de outras fontes (outro buscador, fotos próprias, etc)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21c63e2a",
      "metadata": {
        "id": "21c63e2a"
      },
      "outputs": [],
      "source": [
        "# Seu código aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47dcc795"
      },
      "source": [
        "# Task\n",
        "Create a PyTorch Dataset with data augmentation and batch loading using the images from `data/star_wars` directory, splitting them into training and validation sets. This includes correcting the data splitting call, defining data transformations (resize, random crop, horizontal flip, color jitter, normalization for training; resize, center crop, normalization for validation), implementing a custom `torch.utils.data.Dataset` class, and instantiating `torch.utils.data.DataLoader` for both training and validation sets."
      ],
      "id": "47dcc795"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "517476a9"
      },
      "source": [
        "## Corrigir divisão de dados\n",
        "\n",
        "### Subtask:\n",
        "Ajustar a chamada da função `split_train_val` para que ela processe o diretório correto onde as imagens foram baixadas (`data/star_wars`), em vez de um caminho inexistente.\n"
      ],
      "id": "517476a9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e49a533"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous execution of `split_train_val` failed due to a `FileNotFoundError` because the `root_dir` argument was incorrectly set to `'batch_data'`. The images were downloaded to `data/star_wars`, so the function call needs to be updated to reflect the correct directory to allow the data splitting to proceed successfully.\n",
        "\n"
      ],
      "id": "0e49a533"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}